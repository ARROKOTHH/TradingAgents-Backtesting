"""
ä¾§è¾¹æ ç»„ä»¶
"""

import streamlit as st
import os
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from web.utils.persistence import load_model_selection, save_model_selection

logger = logging.getLogger(__name__)

def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""

    # æ·»åŠ localStorageæ”¯æŒçš„JavaScript
    st.markdown("""
    <script>
    // ä¿å­˜åˆ°localStorage
    function saveToLocalStorage(key, value) {
        localStorage.setItem('tradingagents_' + key, value);
        console.log('Saved to localStorage:', key, value);
    }

    // ä»localStorageè¯»å–
    function loadFromLocalStorage(key, defaultValue) {
        const value = localStorage.getItem('tradingagents_' + key);
        console.log('Loaded from localStorage:', key, value || defaultValue);
        return value || defaultValue;
    }

    // é¡µé¢åŠ è½½æ—¶æ¢å¤è®¾ç½®
    window.addEventListener('load', function() {
        console.log('Page loaded, restoring settings...');
    });
    </script>
    """, unsafe_allow_html=True)

    # ä¼˜åŒ–ä¾§è¾¹æ æ ·å¼
    st.markdown("""
    <style>
    /* ä¼˜åŒ–ä¾§è¾¹æ å®½åº¦ - è°ƒæ•´ä¸º320px */
    section[data-testid="stSidebar"] {
        width: 320px !important;
        min-width: 320px !important;
        max-width: 320px !important;
    }

    /* ä¼˜åŒ–ä¾§è¾¹æ å†…å®¹å®¹å™¨ */
    section[data-testid="stSidebar"] > div {
        width: 320px !important;
        min-width: 320px !important;
        max-width: 320px !important;
    }

    /* å¼ºåˆ¶å‡å°‘ä¾§è¾¹æ å†…è¾¹è· - å¤šç§é€‰æ‹©å™¨ç¡®ä¿ç”Ÿæ•ˆ */
    section[data-testid="stSidebar"] .block-container,
    section[data-testid="stSidebar"] > div > div,
    .css-1d391kg,
    .css-1lcbmhc,
    .css-1cypcdb {
        padding-top: 0.75rem !important;
        padding-left: 0.5rem !important;
        padding-right: 0.5rem !important;
        padding-bottom: 0.75rem !important;
    }

    /* ä¾§è¾¹æ å†…æ‰€æœ‰å…ƒç´ çš„è¾¹è·æ§åˆ¶ */
    section[data-testid="stSidebar"] * {
        box-sizing: border-box !important;
    }

    /* ä¼˜åŒ–selectboxå®¹å™¨ */
    section[data-testid="stSidebar"] .stSelectbox {
        margin-bottom: 0.4rem !important;
        width: 100% !important;
    }

    /* ä¼˜åŒ–selectboxä¸‹æ‹‰æ¡† - è°ƒæ•´ä¸ºé€‚åˆ320px */
    section[data-testid="stSidebar"] .stSelectbox > div > div,
    section[data-testid="stSidebar"] .stSelectbox [data-baseweb="select"] {
        width: 100% !important;
        min-width: 260px !important;
        max-width: 280px !important;
    }

    /* ä¼˜åŒ–ä¸‹æ‹‰æ¡†é€‰é¡¹æ–‡æœ¬ */
    section[data-testid="stSidebar"] .stSelectbox label {
        font-size: 0.85rem !important;
        font-weight: 600 !important;
        margin-bottom: 0.2rem !important;
    }

    /* ä¼˜åŒ–æ–‡æœ¬è¾“å…¥æ¡† */
    section[data-testid="stSidebar"] .stTextInput > div > div > input {
        font-size: 0.8rem !important;
        padding: 0.3rem 0.5rem !important;
        width: 100% !important;
    }

    /* ä¼˜åŒ–æŒ‰é’®æ ·å¼ */
    section[data-testid="stSidebar"] .stButton > button {
        width: 100% !important;
        font-size: 0.8rem !important;
        padding: 0.3rem 0.5rem !important;
        margin: 0.1rem 0 !important;
        border-radius: 0.3rem !important;
    }

    /* ä¼˜åŒ–æ ‡é¢˜æ ·å¼ */
    section[data-testid="stSidebar"] h3 {
        font-size: 1rem !important;
        margin-bottom: 0.5rem !important;
        margin-top: 0.3rem !important;
        padding: 0 !important;
    }

    /* ä¼˜åŒ–infoæ¡†æ ·å¼ */
    section[data-testid="stSidebar"] .stAlert {
        padding: 0.4rem !important;
        margin: 0.3rem 0 !important;
        font-size: 0.75rem !important;
    }

    /* ä¼˜åŒ–markdownæ–‡æœ¬ */
    section[data-testid="stSidebar"] .stMarkdown {
        margin-bottom: 0.3rem !important;
        padding: 0 !important;
    }

    /* ä¼˜åŒ–åˆ†éš”çº¿ */
    section[data-testid="stSidebar"] hr {
        margin: 0.75rem 0 !important;
    }

    /* ç¡®ä¿ä¸‹æ‹‰æ¡†é€‰é¡¹å®Œå…¨å¯è§ - è°ƒæ•´ä¸ºé€‚åˆ320px */
    .stSelectbox [data-baseweb="select"] {
        min-width: 260px !important;
        max-width: 280px !important;
    }

    /* ä¼˜åŒ–ä¸‹æ‹‰æ¡†é€‰é¡¹åˆ—è¡¨ */
    .stSelectbox [role="listbox"] {
        min-width: 260px !important;
        max-width: 290px !important;
    }

    /* é¢å¤–çš„è¾¹è·æ§åˆ¶ - ç¡®ä¿å·¦å³è¾¹è·å‡å° */
    .sidebar .element-container {
        padding: 0 !important;
        margin: 0.2rem 0 !important;
    }

    /* å¼ºåˆ¶è¦†ç›–é»˜è®¤æ ·å¼ */
    .css-1d391kg .element-container {
        padding-left: 0.5rem !important;
        padding-right: 0.5rem !important;
    }
    </style>
    """, unsafe_allow_html=True)

    with st.sidebar:
        # ä½¿ç”¨ç»„ä»¶æ¥ä»localStorageè¯»å–å¹¶åˆå§‹åŒ–session state
        st.markdown("""
        <div id="localStorage-reader" style="display: none;">
            <script>
            // ä»localStorageè¯»å–è®¾ç½®å¹¶å‘é€ç»™Streamlit
            const provider = loadFromLocalStorage('llm_provider', 'dashscope');
            const category = loadFromLocalStorage('model_category', 'openai');
            const model = loadFromLocalStorage('llm_model', '');

            // é€šè¿‡è‡ªå®šä¹‰äº‹ä»¶å‘é€æ•°æ®
            window.parent.postMessage({
                type: 'localStorage_data',
                provider: provider,
                category: category,
                model: model
            }, '*');
            </script>
        </div>
        """, unsafe_allow_html=True)

        # ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½é…ç½®
        saved_config = load_model_selection()

        # Initialize session state, prioritizing saved config
        if 'llm_provider' not in st.session_state:
            st.session_state.llm_provider = saved_config.get('provider', 'dashscope')
        if 'model_category' not in st.session_state:
            st.session_state.model_category = saved_config.get('category', 'openai')
        if 'quick_think_llm' not in st.session_state:
            st.session_state.quick_think_llm = saved_config.get('quick_model') or saved_config.get('model', 'qwen-turbo')
        if 'deep_think_llm' not in st.session_state:
            st.session_state.deep_think_llm = saved_config.get('deep_model') or saved_config.get('model', 'qwen-plus-latest')

        # æ˜¾ç¤ºå½“å‰session stateçŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰
        logger.debug(f"ğŸ” [Session State] å½“å‰çŠ¶æ€ - provider: {st.session_state.llm_provider}, category: {st.session_state.model_category}, quick_model: {st.session_state.quick_think_llm}, deep_model: {st.session_state.deep_think_llm}")

        # AIæ¨¡å‹é…ç½®
        st.markdown("### ğŸ§  AIæ¨¡å‹é…ç½®")

        # LLMæä¾›å•†é€‰æ‹©
        llm_provider = st.selectbox(
            "LLMæä¾›å•†",
            options=["dashscope", "deepseek", "google", "openai", "openrouter", "siliconflow","custom_openai"],
            index=["dashscope", "deepseek", "google", "openai", "openrouter","siliconflow", "custom_openai"].index(st.session_state.llm_provider) if st.session_state.llm_provider in ["siliconflow", "dashscope", "deepseek", "google", "openai", "openrouter", "custom_openai"] else 0,
            format_func=lambda x: {
                "dashscope": "ğŸ‡¨ğŸ‡³ é˜¿é‡Œç™¾ç‚¼",
                "deepseek": "ğŸš€ DeepSeek V3",
                "google": "ğŸŒŸ Google AI",
                "openai": "ğŸ¤– OpenAI",
                "openrouter": "ğŸŒ OpenRouter",
                "siliconflow": "ğŸ‡¨ğŸ‡³ ç¡…åŸºæµåŠ¨",
                "custom_openai": "ğŸ”§ è‡ªå®šä¹‰OpenAIç«¯ç‚¹"
            }[x],
            help="é€‰æ‹©AIæ¨¡å‹æä¾›å•†",
            key="llm_provider_select"
        )

        # æ›´æ–°session stateå’ŒæŒä¹…åŒ–å­˜å‚¨
        if st.session_state.llm_provider != llm_provider:
            logger.info(f"ğŸ”„ [Persistence] æä¾›å•†å˜æ›´: {st.session_state.llm_provider} â†’ {llm_provider}")
            st.session_state.llm_provider = llm_provider
            # æä¾›å•†å˜æ›´æ—¶æ¸…ç©ºæ¨¡å‹é€‰æ‹©
            st.session_state.llm_model = ""
            st.session_state.model_category = "openai"  # é‡ç½®ä¸ºé»˜è®¤ç±»åˆ«
            logger.info(f"ğŸ”„ [Persistence] æ¸…ç©ºæ¨¡å‹é€‰æ‹©")

            # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            save_model_selection(llm_provider, st.session_state.model_category, "")
        else:
            st.session_state.llm_provider = llm_provider

        # æ ¹æ®æä¾›å•†æ˜¾ç¤ºä¸åŒçš„æ¨¡å‹é€‰é¡¹
        if llm_provider == "dashscope":
            quick_think_options = ["qwen-turbo", "qwen-plus-latest", "qwen-max"]
            deep_think_options = ["qwen-plus-latest", "qwen-max", "qwen-turbo"]
            
            quick_think_llm = st.selectbox(
                "å¿«é€Ÿæ€è€ƒæ¨¡å‹",
                options=quick_think_options,
                index=0, # Default to turbo
                format_func=lambda x: f"âš¡ {x}"
            )
            deep_think_llm = st.selectbox(
                "æ·±åº¦æ€è€ƒæ¨¡å‹",
                options=deep_think_options,
                index=0, # Default to plus
                format_func=lambda x: f"ğŸ§  {x}"
            )
            st.session_state.quick_think_llm = quick_think_llm
            st.session_state.deep_think_llm = deep_think_llm
            save_model_selection(llm_provider, "default", quick_think_llm, deep_think_llm)

        elif llm_provider == "google":
            quick_think_options = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-2.5-flash-lite-preview-06-17"]
            deep_think_options = ["gemini-1.5-pro", "gemini-2.5-pro", "gemini-2.0-flash"]

            quick_think_llm = st.selectbox(
                "å¿«é€Ÿæ€è€ƒæ¨¡å‹",
                options=quick_think_options,
                index=0, # Default to flash
                format_func=lambda x: f"âš¡ {x}"
            )
            deep_think_llm = st.selectbox(
                "æ·±åº¦æ€è€ƒæ¨¡å‹",
                options=deep_think_options,
                index=0, # Default to pro
                format_func=lambda x: f"ğŸ§  {x}"
            )
            st.session_state.quick_think_llm = quick_think_llm
            st.session_state.deep_think_llm = deep_think_llm
            save_model_selection(llm_provider, "default", quick_think_llm, deep_think_llm)
        
        # ... (other providers would follow the same pattern) ...

        else:
            st.warning(f"æ¨¡å‹é€‰æ‹©å°šæœªå¯¹ {llm_provider} è¿›è¡Œé€‚é…ã€‚")
            # Fallback to a single model input for un-adapted providers
            llm_model = st.text_input("æ¨¡å‹åç§°", value=st.session_state.get('llm_model', ''))
            st.session_state.quick_think_llm = llm_model
            st.session_state.deep_think_llm = llm_model
            save_model_selection(llm_provider, "default", llm_model, llm_model)
        
        # é«˜çº§è®¾ç½®
        with st.expander("âš™ï¸ é«˜çº§è®¾ç½®"):
            enable_memory = st.checkbox(
                "å¯ç”¨è®°å¿†åŠŸèƒ½",
                value=False,
                help="å¯ç”¨æ™ºèƒ½ä½“è®°å¿†åŠŸèƒ½ï¼ˆå¯èƒ½å½±å“æ€§èƒ½ï¼‰"
            )
            
            enable_debug = st.checkbox(
                "è°ƒè¯•æ¨¡å¼",
                value=False,
                help="å¯ç”¨è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯è¾“å‡º"
            )
            
            max_tokens = st.slider(
                "æœ€å¤§è¾“å‡ºé•¿åº¦",
                min_value=1000,
                max_value=8000,
                value=4000,
                step=500,
                help="AIæ¨¡å‹çš„æœ€å¤§è¾“å‡ºtokenæ•°é‡"
            )
        
        st.markdown("---")

        # ç³»ç»Ÿé…ç½®
        st.markdown("**ğŸ”§ ç³»ç»Ÿé…ç½®**")

        # APIå¯†é’¥çŠ¶æ€
        st.markdown("**ğŸ”‘ APIå¯†é’¥çŠ¶æ€**")

        def validate_api_key(key, expected_format):
            """éªŒè¯APIå¯†é’¥æ ¼å¼"""
            if not key:
                return "æœªé…ç½®", "error"

            if expected_format == "dashscope" and key.startswith("sk-") and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "deepseek" and key.startswith("sk-") and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "finnhub" and len(key) >= 20:
                return f"{key[:8]}...", "success"
            elif expected_format == "tushare" and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "google" and key.startswith("AIza") and len(key) >= 32:
                return f"{key[:8]}...", "success"
            elif expected_format == "openai" and key.startswith("sk-") and len(key) >= 40:
                return f"{key[:8]}...", "success"
            elif expected_format == "anthropic" and key.startswith("sk-") and len(key) >= 40:
                return f"{key[:8]}...", "success"
            elif expected_format == "reddit" and len(key) >= 10:
                return f"{key[:8]}...", "success"
            else:
                return f"{key[:8]}... (æ ¼å¼å¼‚å¸¸)", "warning"

        # å¿…éœ€çš„APIå¯†é’¥
        st.markdown("*å¿…éœ€é…ç½®:*")

        # é˜¿é‡Œç™¾ç‚¼
        dashscope_key = os.getenv("DASHSCOPE_API_KEY")
        status, level = validate_api_key(dashscope_key, "dashscope")
        if level == "success":
            st.success(f"âœ… é˜¿é‡Œç™¾ç‚¼: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ é˜¿é‡Œç™¾ç‚¼: {status}")
        else:
            st.error("âŒ é˜¿é‡Œç™¾ç‚¼: æœªé…ç½®")

        # FinnHub
        finnhub_key = os.getenv("FINNHUB_API_KEY")
        status, level = validate_api_key(finnhub_key, "finnhub")
        if level == "success":
            st.success(f"âœ… FinnHub: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ FinnHub: {status}")
        else:
            st.error("âŒ FinnHub: æœªé…ç½®")

        # å¯é€‰çš„APIå¯†é’¥
        st.markdown("*å¯é€‰é…ç½®:*")

        # DeepSeek
        deepseek_key = os.getenv("DEEPSEEK_API_KEY")
        status, level = validate_api_key(deepseek_key, "deepseek")
        if level == "success":
            st.success(f"âœ… DeepSeek: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ DeepSeek: {status}")
        else:
            st.info("â„¹ï¸ DeepSeek: æœªé…ç½®")

        # Tushare
        tushare_key = os.getenv("TUSHARE_TOKEN")
        status, level = validate_api_key(tushare_key, "tushare")
        if level == "success":
            st.success(f"âœ… Tushare: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ Tushare: {status}")
        else:
            st.info("â„¹ï¸ Tushare: æœªé…ç½®")

        # Google AI
        google_key = os.getenv("GOOGLE_API_KEY")
        status, level = validate_api_key(google_key, "google")
        if level == "success":
            st.success(f"âœ… Google AI: {status}")
        elif level == "warning":
            st.warning(f"âš ï¸ Google AI: {status}")
        else:
            st.info("â„¹ï¸ Google AI: æœªé…ç½®")

        # OpenAI (å¦‚æœé…ç½®äº†ä¸”ä¸æ˜¯é»˜è®¤å€¼)
        openai_key = os.getenv("OPENAI_API_KEY")
        if openai_key and openai_key != "your_openai_api_key_here":
            status, level = validate_api_key(openai_key, "openai")
            if level == "success":
                st.success(f"âœ… OpenAI: {status}")
            elif level == "warning":
                st.warning(f"âš ï¸ OpenAI: {status}")

        # Anthropic (å¦‚æœé…ç½®äº†ä¸”ä¸æ˜¯é»˜è®¤å€¼)
        anthropic_key = os.getenv("ANTHROPIC_API_KEY")
        if anthropic_key and anthropic_key != "your_anthropic_api_key_here":
            status, level = validate_api_key(anthropic_key, "anthropic")
            if level == "success":
                st.success(f"âœ… Anthropic: {status}")
            elif level == "warning":
                st.warning(f"âš ï¸ Anthropic: {status}")

        st.markdown("---")

        # ç³»ç»Ÿä¿¡æ¯
        st.markdown("**â„¹ï¸ ç³»ç»Ÿä¿¡æ¯**")
        
        st.info(f"""
        **ç‰ˆæœ¬**: cn-0.1.13
        **æ¡†æ¶**: Streamlit + LangGraph
        **AIæ¨¡å‹**: 
         - âš¡ {st.session_state.quick_think_llm}
         - ğŸ§  {st.session_state.deep_think_llm}
        **æ•°æ®æº**: Tushare + FinnHub API
        """)
        
        # å¸®åŠ©é“¾æ¥
        st.markdown("**ğŸ“š å¸®åŠ©èµ„æº**")
        
        st.markdown("""
        - [ğŸ“– ä½¿ç”¨æ–‡æ¡£](https://github.com/TauricResearch/TradingAgents)
        - [ğŸ› é—®é¢˜åé¦ˆ](https://github.com/TauricResearch/TradingAgents/issues)
        - [ğŸ’¬ è®¨è®ºç¤¾åŒº](https://github.com/TauricResearch/TradingAgents/discussions)
        - [ğŸ”§ APIå¯†é’¥é…ç½®](../docs/security/api_keys_security.md)
        """)
    
    # ç¡®ä¿è¿”å›session stateä¸­çš„å€¼ï¼Œè€Œä¸æ˜¯å±€éƒ¨å˜é‡
    final_provider = st.session_state.llm_provider
    quick_model = st.session_state.quick_think_llm
    deep_model = st.session_state.deep_think_llm

    logger.debug(f"ğŸ”„ [Session State] è¿”å›é…ç½® - provider: {final_provider}, quick: {quick_model}, deep: {deep_model}")

    return {
        'llm_provider': final_provider,
        'quick_think_llm': quick_model,
        'deep_think_llm': deep_model,
        'enable_memory': enable_memory,
        'enable_debug': enable_debug,
        'max_tokens': max_tokens
    }
